On Extractive and Abstractive Neural Document Summarization with Transformer Language Models
https://arxiv.org/pdf/1909.03186.pdf

Faithful to the Original - Fact Aware Neural Abstractive Summarization
Augment the attention mechanism of neural models with factual triples extracted with open information extraction system


Ensure the Correctness of the Summary: Incorporate Entailment Knowledge into Abstractive Sentence Summarization
entailment aware encoder (MTL) and entailment aware decoder (Entailment reward maximisation)


Evaluating the Factual Consistency of Abstractive Text Summarization
Weakly supervised fact verification model


Assessing The Factual Accuracy of Generated Text
compared different information extraction systems to evaluate the factual accuracy of generated text.


Optimizing the Factual Correctness of a Summary: A Study of Summarizing Radiology Reports


Retrieve, Rerank and Rewrite - Soft Template Based Neural Summarization


Ranking Generated Summaries by Correctness: An Interesting but Challenging Application for Natural Language Inference
Studied whether existing natural language infer- ence systems can be used to evaluate the factual correctness of generated summaries, and found models trained on existing datasets to be inade- quate for this task.


GENERATING WIKIPEDIA BY SUMMARIZING LONG SEQUENCES
Also, we found this very relevant paper that does something similar to our core idea- extract crucial parts from long documents, and then use abstractive ways to summarize. However, they used simple extractive methods for first stage filtering whereas our ideas can be fancier and incorporate more intuition about 'facts'. Also, they have used older SOTA models for step 2 (abstractive summarization) whereas we have better alternatives available now. They also hint at "..results...suggesting future work in improving the extraction step could result in significant improvements. One possibility is to train a supervised model to predict relevance which we leave as future work". Their major contribution is to modify the transformer architecture to introduce a Transformer decoder which supports really long documents, however, they did this for multi-document summarization scenario. They also mention "for our task optimizing for perplexity correlates with increased ROUGE and human judgment. As perplexity decreases we see improvements in the model outputs, in terms of fluency, factual accuracy, and narrative complexity"  so proceeding with the perplexity idea (for extractor) we discussed last time could be good. 

Bottom-Up Abstractive Summarization
